ReversingLabs technical questions
Time taken to solve the written test is not evaluated and will not be the reason for candidate
disqualification. We hire all candidates who successfully pass the interview process, so you are
not competing with other candidates.

1. How would you print a 1M-th line in a file that has 5M lines?
    head -1000000 filename | tail +1000000
    sed -n '1000000p' filename
2. How would you print all data that are between two specific strings, like "car" and
"banana", from a single file?
    sed -n '/car/, /banana/{ /car/! {/banana/!p }}' filename
3. How would you print 10 lines after a specific string, like "car", from a single file?
	awk '/car/{x=NR+1}(NR<=x){print}' filename
    sed -n '/car/,+10p' filename
4. How would you print all lines after line 99999?
    sed -n '99999,$p' filename
5. What is the difference between a deployment, daemonset and statefulset and explain in
which scenario would you use each of them:
    Deployments are used for stateless applications that can be easily replaced or destroyed.
    Daemonsets are used for running pods on every node in the cluster. 
    Statefulsets are used for stateful applications that require stable network identifiers and persistent storage.
6. How would you expose a password to a specific microservice inside a k8s cluster?
    Using a secret object and mapping it to ConfigMap.
7. How would you implement a load balancer on k8s on a self-hosted cluster?
    Use an ingress controller: An ingress controller is a Kubernetes resource that manages inbound traffic to your cluster. 
    It typically runs as a pod on your cluster and can route traffic to different services based on the request URL. 
    There are many open-source ingress controllers available, such as Nginx, Traefik, and Istio, which can be deployed on your cluster. 
    Ingress controllers can be configured to use a variety of load-balancing algorithms, such as round-robin or least connections, to distribute traffic among your pods.

8. What's the difference between ClusterIP, NodePort, LoadBalancer and Ingress
Resource?
    ClusterIP: A ClusterIP service provides a stable IP address for accessing a set of pods within the cluster. This is the default service type and is used for internal communication between pods within the cluster. A ClusterIP service is not accessible from outside the cluster.
    NodePort: A NodePort service exposes a set of pods to the network by opening a specific port on each node in the cluster. This makes the service accessible from outside the cluster, but it can also expose all pods on the same port, which may be a security risk. NodePort services are typically used for development or testing purposes.
    LoadBalancer: A LoadBalancer service provides a load balancer for distributing traffic to a set of pods. The load balancer is typically an external service provided by a cloud provider or a hardware device. A LoadBalancer service is useful for scaling your application and providing high availability.
    Ingress: An Ingress resource is not a service type, but rather a configuration object that defines rules for routing external traffic to a set of services in the cluster. Ingress resources provide more advanced routing capabilities than NodePort or LoadBalancer services, such as host-based routing and URL-based routing. To use an Ingress resource, you typically need to have an Ingress controller deployed in your cluster.

9. How would you expose PostgreSQL and MongoDB services internally and externally in a
self-hosted K8S cluster?

    To expose PostgreSQL and MongoDB services both internally and externally in a self-hosted Kubernetes cluster, you can use a combination of Kubernetes services and Ingress resources.
    Here are the steps you can follow:
    Deploy the PostgreSQL and MongoDB services: You can deploy the PostgreSQL and MongoDB services as stateful sets or deployments, depending on your requirements. Make sure to configure the services to use a ClusterIP service type, which will provide a stable IP address for accessing the services internally within the cluster.
    Create Kubernetes services for the PostgreSQL and MongoDB services: To expose the PostgreSQL and MongoDB services internally within the cluster, you can create Kubernetes services of type ClusterIP for each service. This will provide a stable IP address for accessing the services from within the cluster.
    Create an Ingress resource for external access: To expose the PostgreSQL and MongoDB services externally, you can create an Ingress resource that routes traffic from the internet to the appropriate service. You will need to deploy an Ingress controller in your cluster, such as Nginx or Traefik, to handle the routing. The Ingress controller should be configured to route traffic to the appropriate Kubernetes service based on the request URL.
    Configure SSL termination: If you want to secure traffic to your PostgreSQL and MongoDB services with SSL, you can configure the Ingress controller to terminate SSL traffic and forward unencrypted traffic to the appropriate service.
    In summary, to expose PostgreSQL and MongoDB services internally and externally in a self-hosted Kubernetes cluster, you can create ClusterIP services to provide internal access, and use an Ingress resource to provide external access. The Ingress controller should be configured to route traffic to the appropriate Kubernetes service based on the request URL, and SSL termination can be configured to secure traffic.


10. How would you count all open connections to port 5555 every sec?
    while true; do netstat -an | grep :5555 | grep -c ESTABLISHED; sleep 1; done
11. Write a crontab rule which will be executed every 5 min
	crontab -e
    */5 * * * * command
12. How to list all cron jobs running under user apache?
    sudo crontab -u apache -l
13. How to close all non-root processes that have been running for more than 10 minutes?
       ps -eo pid,user,etime,args | awk '$2!="root" && $3>10 && !/awk/ {print $1}' | xargs -r kill -9
14. How would you find all files named REVERSING, REVersing and revERSING in the file
system with one command?
    sudo find / -type f -iname '*reversing*'
15. Is it possible to run a https service on port 9000. If not, why?
	It is possible.
16. In Linux, which command would you use to check which application uses port 1234?
	sudo lsof -i :1234
17. How do you add a static route in Linux?
	sudo ip route add <network>/<prefix> via <gateway>
18. What program would you use to send a file to a host running a SSH daemon?
	scp 
19. Which commands would you use to create gziped pg database dump?
	pg_dump mydatabase | gzip > mydatabase.sql.gz
20. How would you allow access to port 1950 on Linux?
	sudo iptables -A INPUT -p tcp --dport 1950 -j ACCEPT

    sudo firewall-cmd --add-port=1950/tcp --permanent
    sudo firewall-cmd --reload
21. How would you check if a port is opened on a remote machine?
    telnet <remote_ip_address> <port>
22. Write a command which will restart the process without killing it?
	systemctl restart <service_name>

23. How would you permanently disable SELinux
    sudo vi /etc/selinux/config
    Change:
    SELINUX=disabled
    Reboot

24. What is setuid bit in chmod command
    When the setuid bit is set on an executable file, the program runs with the privileges of the file owner instead of the user who executed it.
25. In which state is a connection after the TCP handshake is successfully completed?
	ESTABLISHED state
26. Define hardlink and soft link with examples
	A hard link is a direct reference to the physical file on disk.
	Example:
	ln file1 hardlink

    A soft link, or symbolic link, is a reference to the file or directory name, not the physical file itself. It is essentially a shortcut that points to the original file's path(like Shortcut in Windows)
    Example:
    ln -s file1 softlink

Practical tasks
1. Create a dockerfile which creates a simple hello world web application in a docker
container which can be accessed via host machine. Enable https with a self signed
certificate. Attach dockerfile and all the scripts/code used in this task.
Task 1 Directory.
2. Write Ansible playbook which connects to a Linux based server and:
○ install nginx proxy server 
■ configure nginx server as a reverse proxy with 3 upstream servers (they
don't need to exist). Each of the first two receives 30% of the traffic. The
third one gets 40%. 
■ configure nginx to add additional response header named RL with value
SRE 
■ configure rate limit of 10 requests per second for the api location  
■ disable access to /phpinfo.php file 
○ configure ssh server to only work with key files 
○ install postgres server
■ create database "rl_test"
■ create read only user named rlusr and grant access to rl_test database

